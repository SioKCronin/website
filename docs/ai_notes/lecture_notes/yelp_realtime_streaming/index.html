<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Siobhán K Cronin  | Yelp Realtime Streaming Data Infrastructure</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.41" />
    
    
      <META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
    

    
    
      <link href="https://siobhankcronin.com/dist/css/app.ab4b67a3ea25990fa8279f3b7ef08b61.css" rel="stylesheet">
    

    
      <link rel="stylesheet" href="https://siobhankcronin.com/css/override.css">
    

    
        <link rel="stylesheet"
          href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    

    
      
    

    

    <meta property="og:title" content="Yelp Realtime Streaming Data Infrastructure" />
<meta property="og:description" content="Fast Order Search Using Yelp&rsquo;s Data Pipeline and Elasticsearch Yelp was experiencing drag on their food order history page due to database lookups. Each lookup required a join across four tables. They found they needed both a relational data store and a key-value store for lantency-sensitive, high-traffic contexts. They also wanted to support full-text search across their data. After weighing their options, they chose Elasticsearch.
Deciding on their schema took some planning, as they wanted to prevent the number of joins of common operations (that was the situation that led to the change in the first place!" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://siobhankcronin.com/ai_notes/lecture_notes/yelp_realtime_streaming/" />
















<meta itemprop="name" content="Yelp Realtime Streaming Data Infrastructure">
<meta itemprop="description" content="Fast Order Search Using Yelp&rsquo;s Data Pipeline and Elasticsearch Yelp was experiencing drag on their food order history page due to database lookups. Each lookup required a join across four tables. They found they needed both a relational data store and a key-value store for lantency-sensitive, high-traffic contexts. They also wanted to support full-text search across their data. After weighing their options, they chose Elasticsearch.
Deciding on their schema took some planning, as they wanted to prevent the number of joins of common operations (that was the situation that led to the change in the first place!">



<meta itemprop="wordCount" content="1511">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Yelp Realtime Streaming Data Infrastructure"/>
<meta name="twitter:description" content="Fast Order Search Using Yelp&rsquo;s Data Pipeline and Elasticsearch Yelp was experiencing drag on their food order history page due to database lookups. Each lookup required a join across four tables. They found they needed both a relational data store and a key-value store for lantency-sensitive, high-traffic contexts. They also wanted to support full-text search across their data. After weighing their options, they chose Elasticsearch.
Deciding on their schema took some planning, as they wanted to prevent the number of joins of common operations (that was the situation that led to the change in the first place!"/>

      
    
  </head>

  <body class="ma0 avenir bg-white-90">

    
   
  

  <header>
    <div class="bg-sio-yellow">
      <nav class="bb bw2 b--mid-gray pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://siobhankcronin.com/" class="f3 fw6 no-underline black dib">
      Siobhán K Cronin
    </a>
    <div class="flex-l items-center">
      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/speaking" title="Speaking page">
              Speaking
            </a>
          </li>
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/projects" title="Projects page">
              Projects
            </a>
          </li>
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/index.html" title="AI Notes page">
              AI Notes
            </a>
          </li>
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/about" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
        </ul>
      
      



  <a href="//twitter.com/siokcronin" class="link-transition twitter link dib z-999 pt3 pr1 pt0-l mr2" title="Twitter link">
    <svg height="20px"  width="20px"  aria-labelledby="simpleicons-twitter-icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title id="simpleicons-twitter-icon">Twitter icon</title><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"/></svg>

  </a>




  <a href="//linkedin.com/in/siobhankcronin" class="link-transition linkedin link dib z-999 pt3 pr1 pt0-l mr2" title="LinkedIn link">
    <svg height="20px"  width="20px"  aria-labelledby="simpleicons-linkedin-icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title id="simpleicons-linkedin-icon">LinkedIn icon</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>

  </a>


  <a href="//github.com/siokcronin" class="link-transition github link dib z-999 pt3 pr1 pt0-l mr2" title="Github link">
    <svg height="20px"  width="20px"  aria-labelledby="simpleicons-github-icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title id="simpleicons-github-icon">GitHub icon</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>

  </a>


  <a href="//medium.com/@siobhankcronin" class="link-transition medium link dib z-999 pt3 pt0-l mr2" title="Medium link">
    <svg height="20px"  width="20px" aria-labelledby="simpleicons-medium-icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title id="simpleicons-medium-icon">Medium icon</title><path d="M2.846 6.36c.03-.295-.083-.586-.303-.784l-2.24-2.7v-.403H7.26l5.378 11.795 4.728-11.795H24v.403l-1.917 1.837c-.165.126-.247.333-.213.538v13.5c-.034.204.048.41.213.537l1.87 1.837v.403h-9.41v-.403l1.937-1.882c.19-.19.19-.246.19-.538V7.794l-5.39 13.688h-.727L4.278 7.794v9.174c-.052.386.076.774.347 1.053l2.52 3.06v.402H0v-.403l2.52-3.06c.27-.278.39-.67.326-1.052V6.36z"/></svg>

  </a>



    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  <article class="flex-l flex-wrap justify-between center">
    <header class="pt4 pa3 ph4-ns pb0 w-100 w-60-ns center">
      <p class="f6 b helvetica tracked">
          
        LECTURE NOTES
      </p>
      <h1 class="f1 helvetica mb1">Yelp Realtime Streaming Data Infrastructure</h1>
    </header>

    <main class="w-100 w-60-ns center nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pt4 pa3 ph4-ns pb0">

<h2 id="fast-order-search-using-yelp-s-data-pipeline-and-elasticsearch">Fast Order Search Using Yelp&rsquo;s Data Pipeline and Elasticsearch</h2>

<p>Yelp was experiencing drag on their food order history page due to database lookups.
Each lookup required a join across four tables. They found they needed both a relational
data store and a key-value store for lantency-sensitive, high-traffic contexts.
They also wanted to support full-text search across their data. After weighing their
options, they chose Elasticsearch.</p>

<p>Deciding on their schema took some planning, as they wanted to prevent the number
of joins of common operations (that was the situation that led to the change in the first place!).
They sureveyed their clients, and thought about possible future use cases. Yelp persists
MySQL writes to Kafka topics, a topic tracking changes for each table. That provides
a lot of useful data, but how would we reconstruct high level order updates from those topics?</p>

<p>They explored their data, and saw that high level order changes make changes to their &lsquo;Order&rsquo;
table. &lsquo;Order&rsquo; was a Fact table in their Snowflake schema. This means they could check
to see if new or updates rows were for existing orders (by checking &lsquo;Order&rsquo;). If they found
the document was indeed in a finalized state, they could the row&rsquo;s foreign keys to
create a full denormalized order document.</p>

<p>Let&rsquo;s see how this all comes together with Paastorm, Yelp&rsquo;s in-house stream processor.
An order assembler consumes the Kafka stream of &lsquo;Order&rsquo; updates, references
additional fields from the database, and constructs order documents that can then
be instered into Elasticsearch. These documents are written to their own Kafka topic,
&lsquo;assembled_order&rsquo;. This topic is consumed by Elasticpipe (a connector they built in Flink),
which writes records out to Elasticsearch.</p>

<p>What happens if there is divergence between the &lsquo;assembled_order&rsquo;
topic and Elasticsearch? Elasticsearch has a feature called
<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/coerce.html">type coercion</a> that was used.
They developed their own auditing algorithm to ensure Elasticpipe was performing the
way they expected. This algorithm retrieves, sorts, and dedupes all document ids
that should exist in Elasticsearch by scanning the Kafka topic, and then scan Elasticsearch
for possible missing documents using binary search.</p>

<h2 id="billions-of-messages-a-day">Billions of Messages a Day</h2>

<p>In 2011, Yelp transitioned to a service oriented architecture (SOA), which scaled
to 150 production services by 2014. Here&rsquo;s a fun factoid shared in the blog. Metcale&rsquo;s
Law that the effect of a telecommunications network is proportional to the square
of the number of users connected to the system. This is a shorthand way of characterizing
network effects in complex systems. We can compare this to the services in a SOA.
Ideally we have the effect of all those possible pathways through the system. However,
if we use RESTFul HTTP connections between all pairs of services this will be difficult
to scale.</p>

<p>Since 2016, Yelp has had over 100 million reviews, which raises some unique challenges.
&ldquo;Bulk data applications become service scalability problems&rdquo;. For instance, how would
we handle joins across services? Won&rsquo;t we need to make N service calls for the
<strong><a href="https://secure.phabricator.com/book/phabcontrib/article/n_plus_one/">N+1 Query Problem</a></strong>?</p>

<p>The solution Yelp came up with lies in a message bus and standardized data formatting.
For the bus, Kafka does the heavy lifting, shifting the complexity from $n^2$ to $n$.
They exploit Kafka&rsquo;s log compaction feature, which prunes topics down, and retains
only the most recent message for every key. For formatting, they chose Avro, a
space-efficient binary serialization format that integreates nicely with dynamic languages.
What they exploited in their stream architecture was Avro&rsquo;s schema evolution, which
means that reader and writer applications can use different schema versions, provided
they are compatible. This is very cool! Producers can iterate on their schema, without
effecting consumer applications. Schemas are catalogued in an HTTP schema store called
the &ldquo;Schematizer&rdquo;, so that data can be transported without schemas. Schemas are retrieved
and data is decoded at runtime.</p>

<p>So, with a set of Kafka topics regulated by a Schematizer, Yelp&rsquo;s realtime data pipeline
can provide some important guarentees:
* <strong>format</strong> (registered schema are immutable)
* <strong>compatability</strong> (every active schema assigned to a topic is guarenteed
to be compatible with every other active schema assigned to the same topic)
* <strong>registration</strong> (producers and consumers register whenever they produce or consume
data with a schema, so there is a log of which users are using which schema at what
frequency)
* <strong>data ownership</strong> (all schema require documentation, and a team assignment, which
is exposed through an interface called Watson)
* <strong>data availability</strong> (database change capture can reconstruct a complete snapshot)</p>

<h2 id="using-services-to-break-down-monoliths">Using Services to Break Down Monoliths</h2>

<p>I was remarking to a colleague that I&rsquo;ve entered the field of data engineering
at the height of service oriented architecture, and that I actually need to back up
and learn more about the monoliths from which such systems came. What I&rsquo;ve been enjoying
about the Yelp blog is that they share the points of inflection in their systems.</p>

<p>Here are some of the tools/practices they&rsquo;re using at Yelp to keep their services
humming (and growing):</p>

<ul>
<li><strong>Swagger</strong> documents the interface of HHTP/JSON services. <em>swagger-py</em> will
automatically create a Python client given a Swagger specification, and <em>Swagger UI</em>
provides a centralized directory for all service interfaces.</li>
<li><strong>Docker containers</strong> are used to spin up test instances for services, creating
images that can be pulled in as dependencies by other service authors who wish
to acceptance test the service.</li>
<li><strong>Pyramid</strong> is used as the service stack&rsquo;s web framework, which is a Python
package that &ldquo;makes it easy to write web applications&rdquo;.</li>
<li><strong>gevent</strong> is a coroutine-based Python networking library providing a high-level
synchronous API</li>
<li><strong>SmartStack</strong> backs the service discovery system, with each client host running
an HAProxy instance bound to a localhost. A client contacts a service by connecting
to its localhost load balancer which then proxies the request to a service instance.</li>
<li><strong>SQLAlchemy</strong> is used as the database access layer.</li>
<li><strong>uWSGI</strong> is used behind all the hosting services.</li>
</ul>

<h2 id="more-than-just-a-schema-store">More than Just a Schema Store</h2>

<p>Being out in front of the curve has its advantages, but in tech that can sometimes
mean you are building and maintaining software that will one day be a big fancy
open source project others can plug and play with. Such was the case when Yelp
tackled its schema management. There wasn&rsquo;t a product on the market suited to their
needs, so they built their own solution, the Schematizer (which is the closest
to a data engineering superhero name I&rsquo;ve ever heard).</p>

<p>In the world of NoSQL databases, schemas can get a bad rap. But as Storm&rsquo;s founder
Nathan Marz puts it, schemas force us to deal with exceptions at the time the data
is added, when the context is the most rich as to what might be wrong, as opposed
to handling such misisng or incorrectly formatted data downstream, where the context
is the weakest. When used well, schemas can reduce serious debugging headaches
and ensure consumers receive data in the form they expect.</p>

<p>Yelp uses Avro to represent their schemas, which are defined with JSON. If you&rsquo;re interested
in exploring this landscape, be sure to check out Thrift as well. One of the Avro
features highlighted in this article is schema evolution, which handles what happens
when when Avro schema are changed after data has been written to the data store
using an older version. Here&rsquo;s more <a href="https://docs.oracle.com/database/nosql-11.2.2.0/GettingStartedGuide/schemaevolution.html">info</a> on schema evolution from Oracle. At Yelp, each
schema that strams through the pipeline is serialized with an Avro schema. The message
itself contains a schema ID, so when it reaches the consumer the consumer can retrieve
the appropriate schema from the Schematizer and deserialize the message. Having
all the schemas in one place creates a &ldquo;single point of truth&rdquo;.</p>

<p>An interesting case worth considering is what happens when an upstream producer
changes the schema of the data it passes to the pipeline. How will this affect
consumers downstream? This is addressed by the Schematizer, which determines
topics that can safely be assigned to the new schema based on schema compatibility.
This compatibility is determined by Avro resolution roles, which you can read more
about <a href="http://avro.apache.org/docs/1.8.0/spec.html#Schema+Resolution">here</a>. If you
look through the resolution steps, they&rsquo;re pretty intuitive - the schemas have to
define compatible data structures (i.e. &ldquo;maps whose value types match&rdquo;, or &ldquo;have
the same primitive type&rdquo;). Values from the writer can be &ldquo;promoted&rdquo; to what the
reader expects. For example, <strong>int</strong> is promotable to <strong>long, float</strong> or <strong>double</strong>.</p>

<p>The primary key fields of the schemas in the Schematizer are used for log compaction,
which is useful for restoring state after a crash. Log compaction retains the last
update for each key, and a log compacted Kafka topic log contains a full snapshot
of final record values for every record key. Log compaction allows consumers to restore
their state from the log compacted topic. You can learn more about how log compaction works
<a href="http://cloudurable.com/blog/kafka-architecture-log-compaction/index.html">here</a>.</p>

<p>It&rsquo;s also worth mentioning, that when personally identifiable information (PII) fields
are added to a schema that previously only had non-PII fields, the two schema are
flagged as incompatible, and the Schematizer creates a new topic for the new schema.
This is great feature for controlling access to private information.</p>
<ul class="pa0">
  
</ul>
<div class="mt6">
        
      </div>
    </main>
  </article>

    </main>
    <footer class="bg-near-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://siobhankcronin.com/" >
    &copy; 2018 Siobhán K Cronin
  </a>
  </div>
</footer>

    

  <script src="https://siobhankcronin.com/dist/js/app.3fc0f988d21662902933.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
  

  <script type="text/javascript">
    hljs.initHighlightingOnLoad();
  </script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\[','\]']],
        processEscapes: true,
        processEnvironments: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        TeX: { equationNumbers: { autoNumber: "AMS" },
             extensions: ["AMSmath.js", "AMSsymbols.js"] }
      }
    });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML">
</script>

  </body>
</html>
