<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Siobhán K Cronin  | System design challenge</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.41" />
    
    
      <META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
    

    
    
      <link href="https://siobhankcronin.com/dist/css/app.ab4b67a3ea25990fa8279f3b7ef08b61.css" rel="stylesheet">
    

    
      <link rel="stylesheet" href="https://siobhankcronin.com/css/override.css">
    

    
        <link rel="stylesheet"
          href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    

    
      
    

    

    <meta property="og:title" content="System design challenge" />
<meta property="og:description" content="Infrastructure Software Engineer The following questions were answerd by Siobhan K Cronin.
Question 1 What properties of the CAP theorem would you prioritize for a cloud storage service (e.g. Amazon S3, Google Cloud Storage)? What tradeoffs would you have to make?
I approach the consistency vs. availability trade-off as an opportunity to clarify how our system might best serve our business goals. For example, in systems where it is mission-critical that all users see exactly the same data, such as systems serving critical-care patient medical records, then I would prioritize consistency." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://siobhankcronin.com/ai_notes/software_engineering/github_take_home/" />
















<meta itemprop="name" content="System design challenge">
<meta itemprop="description" content="Infrastructure Software Engineer The following questions were answerd by Siobhan K Cronin.
Question 1 What properties of the CAP theorem would you prioritize for a cloud storage service (e.g. Amazon S3, Google Cloud Storage)? What tradeoffs would you have to make?
I approach the consistency vs. availability trade-off as an opportunity to clarify how our system might best serve our business goals. For example, in systems where it is mission-critical that all users see exactly the same data, such as systems serving critical-care patient medical records, then I would prioritize consistency.">



<meta itemprop="wordCount" content="2345">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="System design challenge"/>
<meta name="twitter:description" content="Infrastructure Software Engineer The following questions were answerd by Siobhan K Cronin.
Question 1 What properties of the CAP theorem would you prioritize for a cloud storage service (e.g. Amazon S3, Google Cloud Storage)? What tradeoffs would you have to make?
I approach the consistency vs. availability trade-off as an opportunity to clarify how our system might best serve our business goals. For example, in systems where it is mission-critical that all users see exactly the same data, such as systems serving critical-care patient medical records, then I would prioritize consistency."/>

      
    
  </head>

  <body class="ma0 avenir bg-white-90">

    
   
  

  <header>
    <div class="bg-sio-yellow">
      <nav class="bb bw2 b--mid-gray pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://siobhankcronin.com/" class="f3 fw6 no-underline black dib">
      Siobhán K Cronin
    </a>
    <div class="flex-l items-center">
      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/projects" title="Projects page">
              Projects
            </a>
          </li>
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/index.html" title="AI Notes page">
              AI Notes
            </a>
          </li>
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/about" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw5 dib pr3">
            <a class="hover-gray no-underline mid-gray" href="/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
        </ul>
      
      



  <a href="//twitter.com/siokcronin" class="link-transition twitter link dib z-999 pt3 pr1 pt0-l mr2" title="Twitter link">
    <svg height="20px"  width="20px"  aria-labelledby="simpleicons-twitter-icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title id="simpleicons-twitter-icon">Twitter icon</title><path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.951.555-2.005.959-3.127 1.184-.896-.959-2.173-1.559-3.591-1.559-2.717 0-4.92 2.203-4.92 4.917 0 .39.045.765.127 1.124C7.691 8.094 4.066 6.13 1.64 3.161c-.427.722-.666 1.561-.666 2.475 0 1.71.87 3.213 2.188 4.096-.807-.026-1.566-.248-2.228-.616v.061c0 2.385 1.693 4.374 3.946 4.827-.413.111-.849.171-1.296.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.319-3.809 2.105-6.102 2.105-.39 0-.779-.023-1.17-.067 2.189 1.394 4.768 2.209 7.557 2.209 9.054 0 13.999-7.496 13.999-13.986 0-.209 0-.42-.015-.63.961-.689 1.8-1.56 2.46-2.548l-.047-.02z"/></svg>

  </a>




  <a href="//linkedin.com/in/siobhankcronin" class="link-transition linkedin link dib z-999 pt3 pr1 pt0-l mr2" title="LinkedIn link">
    <svg height="20px"  width="20px"  aria-labelledby="simpleicons-linkedin-icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title id="simpleicons-linkedin-icon">LinkedIn icon</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>

  </a>


  <a href="//github.com/siokcronin" class="link-transition github link dib z-999 pt3 pr1 pt0-l mr2" title="Github link">
    <svg height="20px"  width="20px"  aria-labelledby="simpleicons-github-icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title id="simpleicons-github-icon">GitHub icon</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>

  </a>


  <a href="//medium.com/@siobhankcronin" class="link-transition medium link dib z-999 pt3 pt0-l mr2" title="Medium link">
    <svg height="20px"  width="20px" aria-labelledby="simpleicons-medium-icon" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title id="simpleicons-medium-icon">Medium icon</title><path d="M2.846 6.36c.03-.295-.083-.586-.303-.784l-2.24-2.7v-.403H7.26l5.378 11.795 4.728-11.795H24v.403l-1.917 1.837c-.165.126-.247.333-.213.538v13.5c-.034.204.048.41.213.537l1.87 1.837v.403h-9.41v-.403l1.937-1.882c.19-.19.19-.246.19-.538V7.794l-5.39 13.688h-.727L4.278 7.794v9.174c-.052.386.076.774.347 1.053l2.52 3.06v.402H0v-.403l2.52-3.06c.27-.278.39-.67.326-1.052V6.36z"/></svg>

  </a>



    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  <article class="flex-l flex-wrap justify-between center">
    <header class="pt4 pa3 ph4-ns pb0 w-100 w-60-ns center">
      <p class="f6 b helvetica tracked">
          
        SOFTWARE ENGINEERING
      </p>
      <h1 class="f1 helvetica mb1">System design challenge</h1>
    </header>

    <main class="w-100 w-60-ns center nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pt4 pa3 ph4-ns pb0">

<h1 id="infrastructure-software-engineer">Infrastructure Software Engineer</h1>

<p>The following questions were answerd by Siobhan K Cronin.</p>

<h2 id="question-1">Question 1</h2>

<p><strong>What properties of the CAP theorem would you prioritize for a cloud storage service
(e.g. Amazon S3, Google Cloud Storage)? What tradeoffs would you have to make?</strong></p>

<p>I approach the consistency vs. availability trade-off as an opportunity to clarify
how our system might best serve our business goals. For example, in systems where
it is mission-critical that all users see exactly the same data, such as
systems serving critical-care patient medical records, then I would prioritize consistency.
However, in services where users expect real-time access to information, such as Yelp &ldquo;closing soon&rdquo;
restaurant recommendations, I would prioritize availability.</p>

<p>This has been my general approach in using the CAP theorem to address tradeoffs in database design,
but I&rsquo;ve been thinking recently about whether the Venn diagram used to depict this &ldquo;theorem&rdquo;
is really accurate. RDBM systems are touted as achieving both consistency and availability while sacrificing
partition tolerance, but is that really true? Is partition tolerance ever a choice?
What was Dr. Eric Brewer really trying to say when he presented CAP theorem in 2000? I turned to Martin Klepperman
<a href="https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html">Please Stop Calling Databases CP or AP</a>
and Coda Hale&rsquo;s
<a href="https://codahale.com/you-cant-sacrifice-partition-tolerance/">You Can&rsquo;t Sacrifice Partition Tolerance</a>
for answers, and here&rsquo;s what I learned.</p>

<p>As Klepperman puts it, <em>partition tolerance</em> essentially means we are &ldquo;communicating
over an asynchronous network that may delay or drop messages&rdquo;, and reminds us that
&ldquo;the internet and all datacenters have this property&rdquo;, so we don&rsquo;t really have a choice.
Hale puts this more directly when he states that &ldquo;for a distributed system to not require
partition tolerance it would have to run on a network which is guarenteed to never
drop messages (or deliver them late) and whose nodes are guarenteed to never die&rdquo;.
We don&rsquo;t live in such a world, so if we are to consider the context the database system
is operating in (which I believe we should), then some degree of partition tolerance
will be a part of any distributed system we design.</p>

<p>It&rsquo;s quite sobering to read through the precise definitions underlying the assertions
of the CAP theorem, and measure just how far those definitions are from the colloquial
use of the same words. Take &ldquo;availability&rdquo; for instance. In the context of CAP,
an available system is defined as one where &ldquo;every request received by a non-failing node in the system must result
in a non-error response&rdquo;. This is a very limited view on avaiability, and says nothing of
nodes that have crashed or are being recovered, software bugs, or systems that have
run out of space. There is a range of desired &ldquo;availability&rdquo; that extend beyond
well beyond the scope of ensuring a resposne from a non-failing node. Turning to consistency,
Hale reminds us that standard data replication is not &ldquo;strongly
consistent&rdquo; as there is inherent lag. Instaneous and global consistency in a distributed
system is impossible, given the physical laws of the universe, but in practice we
typically mean a reduction of lag to a level that is imperceptible.</p>

<p>So, in regards to our cloud-hosted system, knowing that we are already working with
in a partition tolerant environment, I would want to ensure we are clear about the
specific conditions that would compromise the availability of our data (in the
broader-than-CAP sense) while addressing the linearizability (&ldquo;consistency&rdquo;) of
how updates propogate through our system and how these are experienced by our users.</p>

<h2 id="question-2">Question 2</h2>

<p><strong>You are part of a team that is responsible for a large, distributed web application.
Assume the architecture consists of multiple services running on Kubernetes, using
primarily MySQL for persistence, and some form of API and user-facing frontend.
Make whatever other assumptions about the system you wish.</strong></p>

<p>We can assume we have frontend, processing, and database clusters running in each of our
AWS service availability zones where we are servign customers. We can assume we have
load balancers effectively handling traffic to our processing layer, and a CDN
to cache all commonly requested content in these regions, with Least Recently Used (LRU) eviction strategy.
We may also have cache layer behind our servers to support common database lookups and processing requests.</p>

<p>Our data modeling for our MySQL cluster can include a Users table, as well as tabels to
store data and media pointers for all the other amazing things our system does. Writes
to our database cluster can be processed by a master node cluster and written
to our replicas. Reads can happen from any node. MySQL Workbench will be set up for DB monitoring,
and we will enable our <strong>slow-log</strong> by setting the appropriate parameters in the <strong>my.cng</strong> file.
Our Users table will be indexed to ensure speedy lookup during log-in verification.</p>

<p>We will use Docker as our container service and Kubernetes as our container orchestrator.</p>

<p>There are many aspects of our system we could explore, but in order to set up Question 3 well,
let&rsquo;s address the following:</p>

<h4 id="login">Login</h4>

<p>For login, our process can be that if a user is in the user index
and if the hash of their submitted password matches the stored value of their
hashed password, then they are validated and a new session is created. For the hashing
we can use some form of cryptographic hashing function (i.e. Argon2), that is deterministic,
quick to compute, and infeasible to generate the original password from the hash.
This hashed password will be stored in our Users table, and compared
against the hash of the password used at login.</p>

<p>So, the login API might be something like</p>

<pre><code>LOGIN(timestamp, IP, user, password)
</code></pre>

<p>which will send to our verification processor a JSON file.</p>

<pre><code>{ timestamp: '1000-01-01 00:00:00', 
  IP: '127.0.0.1/32',
  user: SioKCronin,
  password: IHeartData
}
</code></pre>

<p>Our verification processor will then process the request.</p>

<pre><code>import argon2
import mysql.connector

user, password = PARSE FROM JSON MESSAGE

mydb = mysql.connector.connect(
  host=&quot;localhost&quot;,
  user=&quot;yourusername&quot;,
  passwd=&quot;yourpassword&quot;,
  database=&quot;mydatabase&quot;
)

password = argon2.argon2_hash(&quot;IHeartData&quot;)

mycursor = mydb.cursor()

mycursor.execute(&quot;SELECT *
                  FROM users
                  WHERE `user` =  {} 
                  AND 'hashed_password' = {},
                  LIMIT = 1&quot;.format(user, password)
                )

myresult = mycursor.fetchall()

if myresult:
    pass
    ```
    Validate and initialize session
    ```
else:
    pass
    ```
    Raise error
    ```
</code></pre>

<h4 id="traffic-volume">Traffic volume</h4>

<p>For traffic volume, I&rsquo;m going to use Yelp&rsquo;s traffic as an example, as their persistence
layer consists of primarily MySQL clusters backed up to Redshift, and they
also orchestrate their deployment of Docker containers with Kubernetes (combined with Mesos
in their in-house system, PaaSTA).</p>

<p>Yelp sees an average of 100 million unique mobile users a month. If we estimate
that 20% of Yelp&rsquo;s users stay logged into the app, these means
there are approximately 80 million users who log in each month.
If we assume the distribution of logins is constant across the entire day, that
would mean an average of 925 logins/second. While Yelp is used globally, the lionshare
of its users are in the United States, and they most likely have observed hours of peak
usage, so it would be safe to assume the number of logins per second could excede
this initial estimate, perhaps extending up to tens of thousands of logins per econd.</p>

<p>This means a large number of users could be negatively impacted by slow login,
especially during peak hours, and, relatedly, any
rollout of software updates must take into account this steady, high-volume traffic.</p>

<h4 id="container-orchestration">Container orchestration</h4>

<p>Since we are using Kubernetes, our system is self-healing. If we have nodes down that are not auto-recovering,
this will point us either to our Kubernetes configuration itself or a problem with our hosted service.</p>

<h4 id="cloud-hosting-and-monitoring">Cloud Hosting and Monitoring</h4>

<p>Let&rsquo;s assume we are using AWS, with a monitoring service like Prometheus for our cluster maintenance.
We will set up a VPN with security groups based on the product ownership areas and
the necessary restrictions for our team.</p>

<h2 id="question-3">Question 3</h2>

<p><strong>Users have recently begun complaining of slowness when logging in. Normally
logins take tens of milliseconds but many users are now seeing logins take
multiple seconds. Given full access to all the necessary systems, what are
your initial steps to investigate?</strong></p>

<p>There are three overarching questions I would like to tackle:</p>

<ul>
<li>what happened?</li>
<li>how can we fix it?</li>
<li>how can we detect it sooner in the future?</li>
</ul>

<h3 id="what-happened">What happened?</h3>

<p><strong>Which users have been affected?</strong></p>

<p>It is imortant to note that users are reporting they are successfully
logging in, it is just taking much longer.</p>

<p>How many users have reported this issue, and what do they have in common? Geography?
Similar user names? Similiar log-in times? Android, IOS, desktop)? If similarities
are encountered, what parts of our system do they point to? Do the similarities relate
to how our DB is sharded, thereby possibly indicating a problem in our load balancing or
pointing to downtime on particular nodes in our cluster? Does the regionality of the issue point to possible
issues in our cloud hosting for that region?</p>

<p>To start investigating, we&rsquo;ll want to look at the slow-log we enabled for our MySQL cluster.</p>

<pre><code class="language-python">mysqldumpslow
</code></pre>

<p>This will give us a view of all recent slow queries, which, depending on the scope of the problem,
will most likely needed to be filtered further. We can do so by adding a few more flags,
such as <strong>-i</strong> for specific node instances (if we have identified any) or return only a select number <strong>-t</strong>.</p>

<p>We can also tag on an <strong>EXPLAIN</strong> to our query, and run it in our dev environment to
check out our query plan. This will give an estimated cost for how long the query
will take and how many rows will need to be scanned. Our login query is rather simple,
so this may not yield anything, but it will be good to rule out an inefficient query plan.</p>

<p><strong>What is the state of our clusters?</strong></p>

<p>For this we can turn to Prometheus and our AWS dashboard. Have any nodes been down
for any significant portion of time? Our system is configured to self-heal, so
if nodes are down, what would be preventing them from firing up?</p>

<p><strong>Traffic surges?</strong></p>

<p>Did our system experience any spikes in traffic? If so, does this surge in traffic
correlate with a known event (marketing push, etc), or is this a possible sign of an attack?</p>

<p>We can check traffic spikes by looking at our AWS dashboard, or whatever monitoring GUI
we have selected for our frontend metrics.</p>

<p>To help narrow in on time windows worth consider, we would be interested in
looking at the logs for recent activity for the users who experienced the lag (or
any demographics we feel may have experienced this, based on our analysis above).
In our MySQL Workbench, we would be interested in looking in teh logs
at key performance indicators relevant to this triage, such as <strong>client timing</strong>,
<strong>network latency</strong>, <strong>server execution timing</strong>, <strong>index usage</strong>, and <strong>number of rows scanned</strong>.</p>

<p>If we find there is indeed a pattern of non-malicious, naturally-occurring increase
in logins that leads to bottlenecks, how can our load balancers and MySQL cluster
partitioning be redesigned to handle such traffic?</p>

<p><strong>Was something recently deployed that correlates with this phenomena?</strong></p>

<p>If we have not encountered an obvious error in our clusters or anomalies in
system traffic that would explain these log-in lags, it is time to evaluate when
did this change begin in order to debug it. Have we recently our code for handling logins?</p>

<p>We can start but running a diff on the container itself</p>

<pre><code>docker diff CONTAINER_ID
</code></pre>

<p>which will indicate which directories in our code base changed in the container.
If we see that login might have changed in some way, we can dive in further to
look at the diff of those files in particular. Maybe there&rsquo;s a straighforward bug?</p>

<h3 id="how-we-can-we-resolve-this-issue">How we can we resolve this issue?</h3>

<p>Let&rsquo;s say we found a bug that was introduced in a recent revsion. We could manually
roll back to a previous version, but we must ask ourselves if restoring
the previous low latency login is more important than the benefits
provided by other feautures included in our last revision (which will be undone if we rollback).
If we choose to rollback, here&rsquo;s how we might proceed.</p>

<p>Like <em>git reset &ndash;hard commitID</em> in git version control, we can roll back
to a specific previous revision in the deployment history.</p>

<p>We can first examine the history to obtain the version number,</p>

<pre><code>kubectl rollout history deployment/nginx-deployment deployments &quot;nginx-deployment&quot;
</code></pre>

<p>and rollback to that specific revision.</p>

<pre><code class="language-python">kubectl rollout undo deployment/nginx-deployment --to-revision=2
deployment.extensions/nginx-deployment
</code></pre>

<p>This will pull the bug out of production, and will allow us to deploy a functional
version of our system while we address the next section (improving testing!).</p>

<h3 id="how-might-we-test-for-such-issues-going-forward">How might we test for such issues going forward?</h3>

<p>What is perhaps most alarming about this problem is that we did not catch it sooner.
We had to wait until our users complained, which is much too late.</p>

<p>It is possible our triage inspection will yield the results we are looking for, and the bug
can be fixed in short order. However, it may also be the case that the problem is more
complex, and will require further troubleshooting. In either case we are going to want
more rigourous test coverage that replicates the conditions that led to the slow
log-in our users experienced. For load testing, we may wish to move forward with a tool
like <a href="https://github.com/twitter/iago">Iago</a>, which excels at accurately replicating
production traffic.</p>

<p>Once we feel we have solved the problem and it passes our tests, including load testing,
then we can set Kubernets to use a canary testing rollout strategy. This will requires us to
set a timeframe under which revisions will be monitored before further rollout takes place.
We should select time windows that afford the system a chance to monitor the kinds of interaction we expect
from our users. Given the volume we are assuming in this system, perhaps we can expect to see
most common activity within a 24 hour timeframe, or perhaps within an hour or minute.
Whatever we chose, these rollouts should be timed such that the new code is exposed
to a typical range of user behavior, so that we can effectively monitor performance.</p>
<ul class="pa0">
  
</ul>
<div class="mt6">
        
      </div>
    </main>
  </article>

    </main>
    <footer class="bg-near-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://siobhankcronin.com/" >
    &copy; 2018 Siobhán K Cronin
  </a>
  </div>
</footer>

    

  <script src="https://siobhankcronin.com/dist/js/app.3fc0f988d21662902933.js"></script>



  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
  

  <script type="text/javascript">
    hljs.initHighlightingOnLoad();
  </script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\[','\]']],
        processEscapes: true,
        processEnvironments: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        TeX: { equationNumbers: { autoNumber: "AMS" },
             extensions: ["AMSmath.js", "AMSsymbols.js"] }
      }
    });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML">
</script>

  </body>
</html>
